{
 "cells": [
  {
   "cell_type": "raw",
   "id": "56b0f3e4-b857-4fa2-b8bf-b4ca6665dec2",
   "metadata": {},
   "source": [
    "corpus     ---> paragraph\n",
    "documents  ---> sentences\n",
    "vecobluery ---> uniqe words\n",
    "words      ---> wordsr"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea71a850-9d48-4304-ad73-1062f0e92c2a",
   "metadata": {},
   "source": [
    "goal -- converting either paragraph or sendentce into word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "398d3c39-7c8a-4372-a4dc-d3be795a77ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Python, one of the most popular programming languages in the world,\n",
    "has created everything from Netflix’s recommendation algorithm to the software that controls self-driving cars.\n",
    "Python is a general-purpose language, used to create a range of applications, including data science,\n",
    "software and web development, automation, and improving the ease of everyday tasks.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb4b4e32-4f86-4f07-a198-3300b29e3d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## corpus(paragraph) into sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f73c1ea-b47f-4668-a2b3-56b117529e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15b20fab-6fe4-443d-8ae4-58aced1e8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c7ad27a-5a0f-4a48-ae0c-e74477373aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python, one of the most popular programming languages in the world,\\nhas created everything from Netflix’s recommendation algorithm to the software that controls self-driving cars.',\n",
       " 'Python is a general-purpose language, used to create a range of applications, including data science,\\nsoftware and web development, automation, and improving the ease of everyday tasks.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f829754f-f0ea-4788-8827-2aae3eb2cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## documents(sentences to  words) - Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aa4e97c-c930-4308-b269-a5087ed2be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3e9eaad-60ba-4d65-8467-436906d17dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', ',', 'one', 'of', 'the', 'most', 'popular', 'programming', 'languages', 'in', 'the', 'world', ',', 'has', 'created', 'everything', 'from', 'Netflix', '’', 's', 'recommendation', 'algorithm', 'to', 'the', 'software', 'that', 'controls', 'self-driving', 'cars', '.']\n",
      "['Python', 'is', 'a', 'general-purpose', 'language', ',', 'used', 'to', 'create', 'a', 'range', 'of', 'applications', ',', 'including', 'data', 'science', ',', 'software', 'and', 'web', 'development', ',', 'automation', ',', 'and', 'improving', 'the', 'ease', 'of', 'everyday', 'tasks', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in document:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "601f6ba6-a8db-461a-8db6-38113d771879",
   "metadata": {},
   "outputs": [],
   "source": [
    "## documents(sentences to  words) - Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b56f8b42-31bb-4b59-b44d-b2cc2a08e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f68985c-14da-43de-bc4a-211ea1041ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', ',', 'one', 'of', 'the', 'most', 'popular', 'programming', 'languages', 'in', 'the', 'world', ',', 'has', 'created', 'everything', 'from', 'Netflix', '’', 's', 'recommendation', 'algorithm', 'to', 'the', 'software', 'that', 'controls', 'self', '-', 'driving', 'cars', '.']\n",
      "['Python', 'is', 'a', 'general', '-', 'purpose', 'language', ',', 'used', 'to', 'create', 'a', 'range', 'of', 'applications', ',', 'including', 'data', 'science', ',', 'software', 'and', 'web', 'development', ',', 'automation', ',', 'and', 'improving', 'the', 'ease', 'of', 'everyday', 'tasks', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in document:\n",
    "    print(wordpunct_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecb6eefb-d2eb-4c1a-9cb0-5d2803d97dbf",
   "metadata": {},
   "source": [
    "Note: In method 1 - 'self-driving' as a single word but splited in  method 2 - 'self','-','driving'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa13f222-bbe5-4df9-ae79-9448632252f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ## documents(sentences to  words) - one more option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca2109e6-69bb-47ee-b649-9c8c8aaab407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e484772-f4cf-4129-bbde-e3ed364ecf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_bank_tokenize = TreebankWordDetokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e46b2f0-d05a-4e5d-9e6e-d933cb5e9ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P y t h o n,   o n e   o f   t h e   m o s t   p o p u l a r   p r o g r a m m i n g   l a n g u a g e s   i n   t h e   w o r l d, \n",
      " h a s   c r e a t e d   e v e r y t h i n g   f r o m   N e t f l i x ’ s   r e c o m m e n d a t i o n   a l g o r i t h m   t o   t h e   s o f t w a r e   t h a t   c o n t r o l s   s e l f - d r i v i n g   c a r s . \n",
      " P y t h o n   i s   a   g e n e r a l - p u r p o s e   l a n g u a g e,   u s e d   t o   c r e a t e   a   r a n g e   o f   a p p l i c a t i o n s,   i n c l u d i n g   d a t a   s c i e n c e, \n",
      " s o f t w a r e   a n d   w e b   d e v e l o p m e n t,   a u t o m a t i o n,   a n d   i m p r o v i n g   t h e   e a s e   o f   e v e r y d a y   t a s k s.\n"
     ]
    }
   ],
   "source": [
    "print(tree_bank_tokenize.tokenize(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a6b49-4836-4af3-b712-30b2fa23f4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8063d03b-d3f6-4aa3-a9cc-906e9f504217",
   "metadata": {},
   "source": [
    "#### NOTE: we mostly used sent tokinize and word tokinize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db86675-6ab6-49e4-82d0-ab84eb3253a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
